{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“ML2021Spring - HW1.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beenleliu/Paddle/blob/master/%E2%80%9CML2021Spring_HW1_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: Heng-Jui Chang\n",
        "\n",
        "Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "Video: TBA\n",
        "\n",
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Get familiar with PyTorch.\n",
        "\n",
        "If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3x1nDkG-Uy"
      },
      "source": [
        "# **Download Data**\n",
        "\n",
        "\n",
        "If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "fc1e93c1-7ad4-47ed-8a4f-2c39bb8763d5"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 29.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 10.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "# **Some Utilities**\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39U_XFX6KOoj"
      },
      "source": [
        "# **Preprocess**\n",
        "\n",
        "We have three kinds of datasets:\n",
        "* `train`: for training\n",
        "* `dev`: for validation\n",
        "* `test`: for testing (w/o target value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-MdwpLL7Dt"
      },
      "source": [
        "## **Dataset**\n",
        "\n",
        "The `COVID19Dataset` below does:\n",
        "* read `.csv` files\n",
        "* extract features\n",
        "* split `covid.train.csv` into train/dev sets\n",
        "* normalize features\n",
        "\n",
        "Finishing `TODO` below might make you pass medium baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data_1 = list(csv.reader(fp))\n",
        "            data1 = np.array(data_1[1:])[:, 1:41].astype(float) #state\n",
        "            data2 = np.array(data_1[1:])[:, 58:59].astype(float) #features1\n",
        "            data3 = np.array(data_1[1:])[:, 76:77].astype(float) #features2\n",
        "            data = np.hstack((data1,data2,data3)) #42条features\n",
        "        \n",
        "        if not target_only:\n",
        "            feats = list(range(42))\n",
        "        else:\n",
        "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            pass\n",
        "            #feats = list(range(2))\n",
        "  \n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            # data: 2700 * 42 (40 stats + features)\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "            \n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlhTlkE7MDo3"
      },
      "source": [
        "## **DataLoader**\n",
        "\n",
        "A `DataLoader` loads data from a given `Dataset` into batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=True):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Deep Neural Network**\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L2 regularization here\n",
        "        return self.criterion(pred, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvFWVjZ5Nvga"
      },
      "source": [
        "# **Train/Dev/Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM8QecJOyqn"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      },
      "source": [
        "## **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pdrhQAO41L"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Setup Hyper-parameters**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "# **Load data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "eb0e1f26-fa3a-4c9c-bcb2-0a1f105bfc3d"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 42)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 42)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "# **Start Training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "9c00cb50-8609-400b-82f7-af3d724682c6"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model (epoch =    1, loss = 246.8781)\n",
            "Saving model (epoch =    2, loss = 11.4420)\n",
            "Saving model (epoch =    5, loss = 4.1466)\n",
            "Saving model (epoch =    6, loss = 1.0891)\n",
            "Saving model (epoch =    7, loss = 0.9768)\n",
            "Saving model (epoch =    8, loss = 0.7686)\n",
            "Saving model (epoch =    9, loss = 0.6290)\n",
            "Saving model (epoch =   10, loss = 0.4250)\n",
            "Saving model (epoch =   11, loss = 0.3879)\n",
            "Saving model (epoch =   12, loss = 0.3745)\n",
            "Saving model (epoch =   13, loss = 0.3328)\n",
            "Saving model (epoch =   14, loss = 0.3166)\n",
            "Saving model (epoch =   15, loss = 0.2978)\n",
            "Saving model (epoch =   16, loss = 0.2777)\n",
            "Saving model (epoch =   17, loss = 0.2684)\n",
            "Saving model (epoch =   18, loss = 0.2497)\n",
            "Saving model (epoch =   19, loss = 0.2385)\n",
            "Saving model (epoch =   20, loss = 0.2266)\n",
            "Saving model (epoch =   21, loss = 0.2138)\n",
            "Saving model (epoch =   22, loss = 0.2060)\n",
            "Saving model (epoch =   23, loss = 0.1954)\n",
            "Saving model (epoch =   24, loss = 0.1872)\n",
            "Saving model (epoch =   25, loss = 0.1792)\n",
            "Saving model (epoch =   26, loss = 0.1718)\n",
            "Saving model (epoch =   27, loss = 0.1646)\n",
            "Saving model (epoch =   28, loss = 0.1591)\n",
            "Saving model (epoch =   29, loss = 0.1528)\n",
            "Saving model (epoch =   30, loss = 0.1461)\n",
            "Saving model (epoch =   31, loss = 0.1420)\n",
            "Saving model (epoch =   32, loss = 0.1364)\n",
            "Saving model (epoch =   33, loss = 0.1313)\n",
            "Saving model (epoch =   34, loss = 0.1291)\n",
            "Saving model (epoch =   35, loss = 0.1223)\n",
            "Saving model (epoch =   36, loss = 0.1186)\n",
            "Saving model (epoch =   37, loss = 0.1161)\n",
            "Saving model (epoch =   38, loss = 0.1102)\n",
            "Saving model (epoch =   39, loss = 0.1073)\n",
            "Saving model (epoch =   40, loss = 0.1046)\n",
            "Saving model (epoch =   41, loss = 0.1004)\n",
            "Saving model (epoch =   42, loss = 0.0965)\n",
            "Saving model (epoch =   43, loss = 0.0954)\n",
            "Saving model (epoch =   44, loss = 0.0920)\n",
            "Saving model (epoch =   45, loss = 0.0886)\n",
            "Saving model (epoch =   46, loss = 0.0872)\n",
            "Saving model (epoch =   47, loss = 0.0839)\n",
            "Saving model (epoch =   48, loss = 0.0811)\n",
            "Saving model (epoch =   49, loss = 0.0800)\n",
            "Saving model (epoch =   50, loss = 0.0770)\n",
            "Saving model (epoch =   51, loss = 0.0750)\n",
            "Saving model (epoch =   52, loss = 0.0729)\n",
            "Saving model (epoch =   53, loss = 0.0716)\n",
            "Saving model (epoch =   54, loss = 0.0691)\n",
            "Saving model (epoch =   55, loss = 0.0672)\n",
            "Saving model (epoch =   56, loss = 0.0658)\n",
            "Saving model (epoch =   57, loss = 0.0643)\n",
            "Saving model (epoch =   58, loss = 0.0616)\n",
            "Saving model (epoch =   60, loss = 0.0585)\n",
            "Saving model (epoch =   62, loss = 0.0556)\n",
            "Saving model (epoch =   63, loss = 0.0549)\n",
            "Saving model (epoch =   64, loss = 0.0538)\n",
            "Saving model (epoch =   65, loss = 0.0521)\n",
            "Saving model (epoch =   66, loss = 0.0520)\n",
            "Saving model (epoch =   67, loss = 0.0496)\n",
            "Saving model (epoch =   68, loss = 0.0487)\n",
            "Saving model (epoch =   69, loss = 0.0478)\n",
            "Saving model (epoch =   70, loss = 0.0467)\n",
            "Saving model (epoch =   71, loss = 0.0451)\n",
            "Saving model (epoch =   72, loss = 0.0442)\n",
            "Saving model (epoch =   73, loss = 0.0434)\n",
            "Saving model (epoch =   74, loss = 0.0418)\n",
            "Saving model (epoch =   75, loss = 0.0418)\n",
            "Saving model (epoch =   76, loss = 0.0404)\n",
            "Saving model (epoch =   77, loss = 0.0393)\n",
            "Saving model (epoch =   78, loss = 0.0388)\n",
            "Saving model (epoch =   79, loss = 0.0376)\n",
            "Saving model (epoch =   80, loss = 0.0373)\n",
            "Saving model (epoch =   81, loss = 0.0360)\n",
            "Saving model (epoch =   82, loss = 0.0357)\n",
            "Saving model (epoch =   83, loss = 0.0344)\n",
            "Saving model (epoch =   84, loss = 0.0343)\n",
            "Saving model (epoch =   85, loss = 0.0331)\n",
            "Saving model (epoch =   86, loss = 0.0325)\n",
            "Saving model (epoch =   87, loss = 0.0323)\n",
            "Saving model (epoch =   88, loss = 0.0307)\n",
            "Saving model (epoch =   89, loss = 0.0307)\n",
            "Saving model (epoch =   90, loss = 0.0301)\n",
            "Saving model (epoch =   91, loss = 0.0292)\n",
            "Saving model (epoch =   92, loss = 0.0284)\n",
            "Saving model (epoch =   94, loss = 0.0272)\n",
            "Saving model (epoch =   95, loss = 0.0270)\n",
            "Saving model (epoch =   96, loss = 0.0266)\n",
            "Saving model (epoch =   97, loss = 0.0259)\n",
            "Saving model (epoch =   98, loss = 0.0250)\n",
            "Saving model (epoch =  100, loss = 0.0239)\n",
            "Saving model (epoch =  102, loss = 0.0232)\n",
            "Saving model (epoch =  103, loss = 0.0230)\n",
            "Saving model (epoch =  104, loss = 0.0225)\n",
            "Saving model (epoch =  105, loss = 0.0222)\n",
            "Saving model (epoch =  106, loss = 0.0216)\n",
            "Saving model (epoch =  107, loss = 0.0214)\n",
            "Saving model (epoch =  108, loss = 0.0209)\n",
            "Saving model (epoch =  109, loss = 0.0204)\n",
            "Saving model (epoch =  110, loss = 0.0201)\n",
            "Saving model (epoch =  111, loss = 0.0197)\n",
            "Saving model (epoch =  112, loss = 0.0194)\n",
            "Saving model (epoch =  113, loss = 0.0191)\n",
            "Saving model (epoch =  114, loss = 0.0185)\n",
            "Saving model (epoch =  115, loss = 0.0185)\n",
            "Saving model (epoch =  116, loss = 0.0179)\n",
            "Saving model (epoch =  117, loss = 0.0178)\n",
            "Saving model (epoch =  118, loss = 0.0174)\n",
            "Saving model (epoch =  119, loss = 0.0172)\n",
            "Saving model (epoch =  120, loss = 0.0168)\n",
            "Saving model (epoch =  121, loss = 0.0165)\n",
            "Saving model (epoch =  122, loss = 0.0163)\n",
            "Saving model (epoch =  123, loss = 0.0161)\n",
            "Saving model (epoch =  124, loss = 0.0157)\n",
            "Saving model (epoch =  125, loss = 0.0156)\n",
            "Saving model (epoch =  126, loss = 0.0151)\n",
            "Saving model (epoch =  128, loss = 0.0149)\n",
            "Saving model (epoch =  129, loss = 0.0145)\n",
            "Saving model (epoch =  130, loss = 0.0144)\n",
            "Saving model (epoch =  131, loss = 0.0142)\n",
            "Saving model (epoch =  132, loss = 0.0139)\n",
            "Saving model (epoch =  133, loss = 0.0138)\n",
            "Saving model (epoch =  134, loss = 0.0136)\n",
            "Saving model (epoch =  135, loss = 0.0133)\n",
            "Saving model (epoch =  136, loss = 0.0132)\n",
            "Saving model (epoch =  137, loss = 0.0130)\n",
            "Saving model (epoch =  138, loss = 0.0130)\n",
            "Saving model (epoch =  139, loss = 0.0126)\n",
            "Saving model (epoch =  140, loss = 0.0125)\n",
            "Saving model (epoch =  141, loss = 0.0123)\n",
            "Saving model (epoch =  142, loss = 0.0122)\n",
            "Saving model (epoch =  143, loss = 0.0121)\n",
            "Saving model (epoch =  144, loss = 0.0118)\n",
            "Saving model (epoch =  145, loss = 0.0118)\n",
            "Saving model (epoch =  146, loss = 0.0117)\n",
            "Saving model (epoch =  147, loss = 0.0114)\n",
            "Saving model (epoch =  148, loss = 0.0114)\n",
            "Saving model (epoch =  149, loss = 0.0111)\n",
            "Saving model (epoch =  151, loss = 0.0108)\n",
            "Saving model (epoch =  153, loss = 0.0107)\n",
            "Saving model (epoch =  154, loss = 0.0105)\n",
            "Saving model (epoch =  155, loss = 0.0105)\n",
            "Saving model (epoch =  156, loss = 0.0103)\n",
            "Saving model (epoch =  158, loss = 0.0101)\n",
            "Saving model (epoch =  160, loss = 0.0100)\n",
            "Saving model (epoch =  161, loss = 0.0098)\n",
            "Saving model (epoch =  163, loss = 0.0096)\n",
            "Saving model (epoch =  164, loss = 0.0095)\n",
            "Saving model (epoch =  166, loss = 0.0093)\n",
            "Saving model (epoch =  168, loss = 0.0092)\n",
            "Saving model (epoch =  170, loss = 0.0091)\n",
            "Saving model (epoch =  172, loss = 0.0089)\n",
            "Saving model (epoch =  174, loss = 0.0088)\n",
            "Saving model (epoch =  175, loss = 0.0087)\n",
            "Saving model (epoch =  177, loss = 0.0086)\n",
            "Saving model (epoch =  178, loss = 0.0085)\n",
            "Saving model (epoch =  180, loss = 0.0083)\n",
            "Saving model (epoch =  182, loss = 0.0083)\n",
            "Saving model (epoch =  183, loss = 0.0082)\n",
            "Saving model (epoch =  184, loss = 0.0082)\n",
            "Saving model (epoch =  185, loss = 0.0081)\n",
            "Saving model (epoch =  186, loss = 0.0080)\n",
            "Saving model (epoch =  189, loss = 0.0078)\n",
            "Saving model (epoch =  192, loss = 0.0077)\n",
            "Saving model (epoch =  194, loss = 0.0077)\n",
            "Saving model (epoch =  196, loss = 0.0076)\n",
            "Saving model (epoch =  197, loss = 0.0076)\n",
            "Saving model (epoch =  199, loss = 0.0074)\n",
            "Saving model (epoch =  201, loss = 0.0073)\n",
            "Saving model (epoch =  204, loss = 0.0072)\n",
            "Saving model (epoch =  207, loss = 0.0072)\n",
            "Saving model (epoch =  209, loss = 0.0071)\n",
            "Saving model (epoch =  210, loss = 0.0071)\n",
            "Saving model (epoch =  211, loss = 0.0071)\n",
            "Saving model (epoch =  212, loss = 0.0070)\n",
            "Saving model (epoch =  213, loss = 0.0070)\n",
            "Saving model (epoch =  215, loss = 0.0069)\n",
            "Saving model (epoch =  218, loss = 0.0068)\n",
            "Saving model (epoch =  220, loss = 0.0068)\n",
            "Saving model (epoch =  221, loss = 0.0068)\n",
            "Saving model (epoch =  222, loss = 0.0067)\n",
            "Saving model (epoch =  224, loss = 0.0067)\n",
            "Saving model (epoch =  225, loss = 0.0066)\n",
            "Saving model (epoch =  227, loss = 0.0065)\n",
            "Saving model (epoch =  231, loss = 0.0064)\n",
            "Saving model (epoch =  235, loss = 0.0063)\n",
            "Saving model (epoch =  238, loss = 0.0063)\n",
            "Saving model (epoch =  241, loss = 0.0062)\n",
            "Saving model (epoch =  246, loss = 0.0062)\n",
            "Saving model (epoch =  247, loss = 0.0061)\n",
            "Saving model (epoch =  249, loss = 0.0061)\n",
            "Saving model (epoch =  250, loss = 0.0061)\n",
            "Saving model (epoch =  252, loss = 0.0061)\n",
            "Saving model (epoch =  253, loss = 0.0060)\n",
            "Saving model (epoch =  254, loss = 0.0060)\n",
            "Saving model (epoch =  256, loss = 0.0060)\n",
            "Saving model (epoch =  257, loss = 0.0060)\n",
            "Saving model (epoch =  259, loss = 0.0059)\n",
            "Saving model (epoch =  264, loss = 0.0058)\n",
            "Saving model (epoch =  269, loss = 0.0058)\n",
            "Saving model (epoch =  272, loss = 0.0058)\n",
            "Saving model (epoch =  273, loss = 0.0057)\n",
            "Saving model (epoch =  279, loss = 0.0057)\n",
            "Saving model (epoch =  281, loss = 0.0056)\n",
            "Saving model (epoch =  286, loss = 0.0056)\n",
            "Saving model (epoch =  289, loss = 0.0056)\n",
            "Saving model (epoch =  291, loss = 0.0055)\n",
            "Saving model (epoch =  295, loss = 0.0054)\n",
            "Saving model (epoch =  300, loss = 0.0054)\n",
            "Saving model (epoch =  306, loss = 0.0054)\n",
            "Saving model (epoch =  308, loss = 0.0053)\n",
            "Saving model (epoch =  311, loss = 0.0053)\n",
            "Saving model (epoch =  324, loss = 0.0052)\n",
            "Saving model (epoch =  326, loss = 0.0052)\n",
            "Saving model (epoch =  329, loss = 0.0051)\n",
            "Saving model (epoch =  340, loss = 0.0051)\n",
            "Saving model (epoch =  352, loss = 0.0050)\n",
            "Saving model (epoch =  354, loss = 0.0050)\n",
            "Saving model (epoch =  356, loss = 0.0050)\n",
            "Saving model (epoch =  371, loss = 0.0050)\n",
            "Saving model (epoch =  374, loss = 0.0049)\n",
            "Saving model (epoch =  377, loss = 0.0049)\n",
            "Saving model (epoch =  383, loss = 0.0049)\n",
            "Saving model (epoch =  384, loss = 0.0049)\n",
            "Saving model (epoch =  386, loss = 0.0049)\n",
            "Saving model (epoch =  390, loss = 0.0049)\n",
            "Saving model (epoch =  394, loss = 0.0048)\n",
            "Saving model (epoch =  396, loss = 0.0048)\n",
            "Saving model (epoch =  401, loss = 0.0048)\n",
            "Saving model (epoch =  413, loss = 0.0047)\n",
            "Saving model (epoch =  420, loss = 0.0047)\n",
            "Saving model (epoch =  422, loss = 0.0047)\n",
            "Saving model (epoch =  426, loss = 0.0047)\n",
            "Saving model (epoch =  428, loss = 0.0046)\n",
            "Saving model (epoch =  440, loss = 0.0046)\n",
            "Saving model (epoch =  452, loss = 0.0046)\n",
            "Saving model (epoch =  456, loss = 0.0046)\n",
            "Saving model (epoch =  462, loss = 0.0046)\n",
            "Saving model (epoch =  465, loss = 0.0046)\n",
            "Saving model (epoch =  468, loss = 0.0045)\n",
            "Saving model (epoch =  476, loss = 0.0045)\n",
            "Saving model (epoch =  481, loss = 0.0045)\n",
            "Saving model (epoch =  488, loss = 0.0045)\n",
            "Saving model (epoch =  492, loss = 0.0045)\n",
            "Saving model (epoch =  499, loss = 0.0044)\n",
            "Saving model (epoch =  508, loss = 0.0044)\n",
            "Saving model (epoch =  510, loss = 0.0044)\n",
            "Saving model (epoch =  513, loss = 0.0044)\n",
            "Saving model (epoch =  522, loss = 0.0044)\n",
            "Saving model (epoch =  525, loss = 0.0044)\n",
            "Saving model (epoch =  534, loss = 0.0043)\n",
            "Saving model (epoch =  548, loss = 0.0043)\n",
            "Saving model (epoch =  560, loss = 0.0043)\n",
            "Saving model (epoch =  565, loss = 0.0042)\n",
            "Saving model (epoch =  585, loss = 0.0042)\n",
            "Saving model (epoch =  593, loss = 0.0042)\n",
            "Saving model (epoch =  607, loss = 0.0042)\n",
            "Saving model (epoch =  609, loss = 0.0041)\n",
            "Saving model (epoch =  634, loss = 0.0041)\n",
            "Saving model (epoch =  636, loss = 0.0041)\n",
            "Saving model (epoch =  642, loss = 0.0041)\n",
            "Saving model (epoch =  665, loss = 0.0041)\n",
            "Saving model (epoch =  667, loss = 0.0041)\n",
            "Saving model (epoch =  678, loss = 0.0040)\n",
            "Saving model (epoch =  707, loss = 0.0040)\n",
            "Saving model (epoch =  709, loss = 0.0039)\n",
            "Saving model (epoch =  751, loss = 0.0039)\n",
            "Saving model (epoch =  771, loss = 0.0039)\n",
            "Saving model (epoch =  778, loss = 0.0039)\n",
            "Saving model (epoch =  783, loss = 0.0039)\n",
            "Saving model (epoch =  791, loss = 0.0039)\n",
            "Saving model (epoch =  798, loss = 0.0039)\n",
            "Saving model (epoch =  824, loss = 0.0038)\n",
            "Saving model (epoch =  841, loss = 0.0038)\n",
            "Saving model (epoch =  882, loss = 0.0038)\n",
            "Saving model (epoch =  901, loss = 0.0038)\n",
            "Saving model (epoch =  909, loss = 0.0038)\n",
            "Saving model (epoch =  917, loss = 0.0038)\n",
            "Saving model (epoch =  950, loss = 0.0037)\n",
            "Saving model (epoch =  970, loss = 0.0037)\n",
            "Saving model (epoch =  982, loss = 0.0037)\n",
            "Saving model (epoch =  996, loss = 0.0037)\n",
            "Saving model (epoch = 1013, loss = 0.0037)\n",
            "Saving model (epoch = 1034, loss = 0.0036)\n",
            "Saving model (epoch = 1069, loss = 0.0036)\n",
            "Saving model (epoch = 1084, loss = 0.0036)\n",
            "Saving model (epoch = 1096, loss = 0.0036)\n",
            "Saving model (epoch = 1108, loss = 0.0036)\n",
            "Saving model (epoch = 1139, loss = 0.0036)\n",
            "Saving model (epoch = 1198, loss = 0.0036)\n",
            "Saving model (epoch = 1214, loss = 0.0036)\n",
            "Saving model (epoch = 1256, loss = 0.0035)\n",
            "Saving model (epoch = 1318, loss = 0.0035)\n",
            "Saving model (epoch = 1337, loss = 0.0035)\n",
            "Saving model (epoch = 1359, loss = 0.0035)\n",
            "Saving model (epoch = 1365, loss = 0.0035)\n",
            "Saving model (epoch = 1406, loss = 0.0035)\n",
            "Saving model (epoch = 1469, loss = 0.0035)\n",
            "Saving model (epoch = 1523, loss = 0.0034)\n",
            "Finished training after 1724 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "75d10d04-b394-46e9-df20-65e6791dbbfe"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "b21e096c-b30d-4966-fec6-cfa6e8a060d4"
      },
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "# **Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "b5c31cc0-9479-495c-edb9-eb3dabc15120"
      },
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving results to pred.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfrVxqJanGpE"
      },
      "source": [
        "# **Hints**\n",
        "\n",
        "## **Simple Baseline**\n",
        "* Run sample code\n",
        "\n",
        "## **Medium Baseline**\n",
        "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
        "\n",
        "## **Strong Baseline**\n",
        "* Feature selection (what other features are useful?)\n",
        "* DNN architecture (layers? dimension? activation function?)\n",
        "* Training (mini-batch? optimizer? learning rate?)\n",
        "* L2 regularization\n",
        "* There are some mistakes in the sample code, can you find them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmCwXgpot3t"
      },
      "source": [
        "# **Reference**\n",
        "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
        "Copying or reusing this code is required to specify the original author. \n",
        "\n",
        "E.g.  \n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
      ]
    }
  ]
}